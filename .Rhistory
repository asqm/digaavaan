??norm.inter
devtools::check()
devtools::check()
devtools::check()
devtools::check()
?summary_lavaan
usethis::use_readme_rmd()
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
fig.path = "man/figures/README-",
out.width = "100%"
)
y6 ~~ y8"
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
fig.path = "man/figures/README-",
out.width = "100%"
)
library(lavaan)
library(digavaan)
devtools::install()
library(lavaan)
library(digavaan)
model <- "
# latent variables
# latent variables
ind60 =~ x1 + x2 + x3
dem60 =~ y1 + y2 + y3 + y4
dem65 =~ y5 + y6 + y7 + y8
# regressions
# regressions
dem60 ~ ind60
dem65 ~ ind60 + dem60
# residual covariances
# residual covariances
y1 ~~ y5
y2 ~~ y4 + y6
y3 ~~ y7
y4 ~~ y8
y6 ~~ y8"
fit <- sem(model, data=PoliticalDemocracy)
# Traditional print
summary(fit)
# Same information but as a data frames
summary_lavaan(fit)
object <- fit
short_sum <- list()
FAKE <- FALSE
if (object@Options$optim.method == "none") {
FAKE <- TRUE
}
if (FAKE) {
short_sum$iter <-
sprintf("lavaan (%s) -- DRY RUN with 0 iterations\n",
utils::packageDescription("lavaan", fields = "Version"))
} else if (object@optim$iterations > 0) {
if (object@optim$converged) {
short_sum$iter <-
sprintf("lavaan (%s) converged normally after %3i iterations\n",
utils::packageDescription("lavaan", fields = "Version"),
object@optim$iterations)
} else {
short_sum$iter <-
c(
sprintf("** WARNING ** lavaan (%s) did NOT converge after %i iterations\n",
utils::packageDescription("lavaan", fields = "Version"),
object@optim$iterations),
"** WARNING ** Estimates below are most likely unreliable\n"
)
}
} else {
short_sum$iter <-
c(
sprintf("** WARNING ** lavaan (%s) model has NOT been fitted\n",
utils::packageDescription("lavaan", fields = "Version")),
"** WARNING ** Estimates below are simply the starting values\n"
)
}
listwise <- FALSE
for (g in 1:object@Data@ngroups) {
if (object@Data@nobs[[1L]] != object@Data@norig[[1L]]) {
listwise <- TRUE
break
}
}
short_sum$n_groups <-
data.frame(
name_group = NA,
used = NA,
total = NA
)
object@Data@ngroups == 1L
short_sum$n_groups[1, 1] <- "Group 1"
short_sum$n_groups[1, 2] <- object@Data@nobs[[1L]]
short_sum$n_groups[1, 3] <- ifelse(listwise,
object@Data@norig[[1L]],
NA_integer_)
short_sum
object@SampleStats@missing.flag
object@Data@ngroups == 1L
short_sum$missing_patterns[1, 1] <- "Group 1"
short_sum$missing_patterns[1, 2] <- object@Data@Mp[[1L]]$npatterns
short_sum
object@Data@Mp[[1L]]$npatterns
short_sum$missing_patterns[1, 1] <- "Group 1"
object@SampleStats@missing.flag
# long tests that I saved before the ifelse statement
new_test <- object@Options$test %in% c("satorra.bentler", "yuan.bentler",
"mean.var.adjusted", "scaled.shifted")
length_object <- length(object@test) > 1L
new_test && length_object
if (new_test && length_object) {
scaled <- TRUE
if (object@Options$test == "scaled.shifted")  shifted <- TRUE else shifted <- FALSE
} else {
scaled <- FALSE
shifted <- FALSE
}
short_sum$estimator_details <-
data.frame(
estimator = NA,
ml = NA,
ml_scaled = NA
)
object@Options$test != "none" && object@Options$estimator != "MML"
short_sum$estimator_details[1, 1] <- "Minimum Function Test Statistic"
short_sum$estimator_details[1, 2] <- object@test[[1]]$stat
short_sum
if (scaled) {
short_sum$estimator_details[1, 3] <- object@test[[2]]$stat
}
short_sum$estimator_details[2, 1] <- "Degrees of freedom"
short_sum$estimator_details[2, 2] <- object@test[[1]]$df
if (scaled) {
if (round(object@test[[2]]$df) == object@test[[2]]$df) {
short_sum$estimator_details[2, 3] <- object@test[[2]]$df
} else {
short_sum$estimator_details[2, 3] <- round(object@test[[2]]$df, 3)
}
}
# Define the p values
if (is.na(object@test[[1]]$df)) {
short_sum$estimator_details[3, 1] <- "P-value"
short_sum$estimator_details[3, 2] <- round(object@test[[1]]$pvalue, 3)
if (scaled) {
short_sum$estimator_details[3, 3] <- round(object@test[[2]]$pvalue, 3)
}
} else if (object@test[[1]]$df > 0) {
# There might be different p values, so here we test
# which one it is, to later name the p value differently
chisq <- object@test[[1]]$refdistr == "chisq"
unknown <-
length(object@test) == 1L &&
object@test[[1]]$refdistr == "unknown"
if (chisq) {
short_sum$estimator_details[3, 1] <- "P-value (Chi-square)"
} else if (unknown) {
short_sum$estimator_details[3, 1] <- "P-value (Unknown)"
} else {
short_sum$estimator_details[3, 1] <- "P-value"
}
short_sum$estimator_details[3, 2] <- round(object@test[[1]]$pvalue, 3)
if (scaled) {
short_sum$estimator_details[3, 3] <- round(object@test[[2]]$pvalue, 3)
}
} else {
if (object@optim$fx > 0) {
short_sum$estimator_details[3, 1] <- "Minimum Function Value"
short_sum$estimator_details[3, 2] <- object@optim$fx
}
}
if (object@Options$test == "bollen.stine") {
short_sum$estimator_details[4, 1] <- "P-value (Bollen-Stine Bootstrap)"
short_sum$estimator_details[4, 2] <- round(object@test[[2]]$pvalue, 3)
}
if (scaled) {
short_sum$estimator_details[5, 3] <- round(object@test[[2]]$scaling.factor, 3)
if (object@Options$test == "yuan.bentler") {
if (object@Options$mimic == "Mplus") {
correction <- "for the Yuan-Bentler correction (Mplus variant)\n"
} else {
correction <- "for the Yuan-Bentler correction\n"
}
} else if (object@Options$test == "satorra.bentler") {
if (object@Options$mimic == "Mplus" && object@Options$estimator == "ML") {
correction <- "for the Satorra-Bentler correction (Mplus variant)\n"
} else if (object@Options$mimic == "Mplus" && object@Options$estimator == "DWLS") {
correction <- "for the Satorra-Bentler correction (WLSM)\n"
} else if (object@Options$mimic == "Mplus" && object@Options$estimator ==  "ULS") {
correction <- "for the Satorra-Bentler correction (ULSM)\n"
} else {
correction <- "for the Satorra-Bentler correction\n"
}
} else if (object@Options$test == "mean.var.adjusted") {
if (object@Options$mimic == "Mplus" && object@Options$estimator == "ML") {
correction <- "for the mean and variance adjusted correction (MLMV)\n"
} else if (object@Options$mimic == "Mplus" && object@Options$estimator == "DWLS") {
correction <- "for the mean and variance adjusted correction (WLSMV)\n"
} else if (object@Options$mimic == "Mplus" && object@Options$estimator == "ULS") {
correction <- "for the mean and variance adjusted correction (ULSMV)\n"
} else {
correction <- "for the mean and variance adjusted correction\n"
}
}
short_sum$estimator_details[5, 1] <-
paste("Scaling correction factor", correction)
}
if (shifted) {
short_sum$shifted_params$df <-
data.frame(
name_group = NA,
shift_parameter = NA
)
if (object@Data@ngroups == 1L) {
short_sum$shifted_params[1, 1] <- "Group 1"
short_sum$shifted_params[1, 2] <- object@test[[2]]$shift.parameter
} else {
for (g in 1:object@Data@ngroups) {
short_sum$shifted_params[g, 1] <- object@Data@group.label[[g]]
short_sum$shifted_params[g, 2] <- object@test[[2]]$shift.parameter[g]
}
}
if (object@Options$mimic == "Mplus" && object@Options$estimator == "DWLS") {
short_sum$shifted_params$notes <-
"for simple second-order correction (WLSMV)"
} else {
short_sum$shifted_params$notes <-
"for simple second-order correction (Mplus variant)"
}
}
if (object@Data@ngroups > 1L) {
short_sum$group_chisq <-
data.frame(
name_group = NA,
chisq = NA,
chisq_scaled = NA
)
for (g in 1:object@Data@ngroups) {
short_sum$group_chisq[g, 1] <- object@Data@group.label[[g]]
short_sum$group_chisq[g, 2] <- round(object@test[[1]]$stat.group[g], 3)
if (scaled) {
short_sum$group_chisq[g, 3] <- object@test[[2]]$stat.group[g]
}
}
}
if (object@Options$estimator == "MML") {
short_sum$fit_measures <-
lavaan:::fitMeasures(object, c("logl", "npar", "aic", "bic",  "bic2"))
}
short_sum
short_sum
devtools::install()
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
fig.path = "man/figures/README-",
out.width = "100%"
)
library(lavaan)
library(digavaan)
model <- "
# latent variables
# latent variables
ind60 =~ x1 + x2 + x3
# latent variables
ind60 =~ x1 + x2 + x3
dem60 =~ y1 + y2 + y3 + y4
# latent variables
ind60 =~ x1 + x2 + x3
dem60 =~ y1 + y2 + y3 + y4
dem65 =~ y5 + y6 + y7 + y8
y2 ~~ y4 + y6
y3 ~~ y7
y4 ~~ y8
y6 ~~ y8"
fit <- sem(model, data=PoliticalDemocracy)
model <- "
# latent variables
ind60 =~ x1 + x2 + x3
dem60 =~ y1 + y2 + y3 + y4
dem65 =~ y5 + y6 + y7 + y8
# regressions
dem60 ~ ind60
dem65 ~ ind60 + dem60
# residual covariances
y1 ~~ y5
y2 ~~ y4 + y6
y3 ~~ y7
y4 ~~ y8
y6 ~~ y8"
fit <- sem(model, data=PoliticalDemocracy)
fit
digavaan:::short_summary_df(fit)
fit <- sem(model, data=PoliticalDemocracy)
summary(fit)
summary_lavaan(fit)
object <- fit
final_list <- list()
if (std.nox)
standardized <- TRUE
header = TRUE; fit.measures = FALSE;
estimates = TRUE; ci = FALSE; fmi = FALSE; standardized = FALSE;
rsquare = FALSE; std.nox = FALSE; modindices = FALSE;
nd = 3L
final_list <- list()
if (std.nox)
standardized <- TRUE
if (header) {
final_list$header <- short_summary_df(object)
}
devtools::load_all()
if (std.nox)
standardized <- TRUE
if (header) {
final_list$header <- short_summary_df(object)
}
final_list
if (fit.measures) {
if (object@Options$test == "none") {
warning("lavaan WARNING: fit measures not available if test = \"none\"\n\n")
} else if (object@optim$npar > 0L && !object@optim$converged) {
warning("lavaan WARNING: fit measures not available if model did not converge\n\n")
} else {
fitted_obj <- lavaan:::fitMeasures(object, fit.measures = "default")
final_list$fitted_measures <- fit_measures_details(fitted_obj)
}
}
if (estimates) {
PE <- parameter_estimates(object, ci = ci, standardized = standardized,
rsquare = rsquare, fmi = fmi, remove.eq = FALSE,
remove.system.eq = TRUE, remove.ineq = FALSE,
remove.def = FALSE, add.attributes = TRUE)
if (standardized && std.nox) {
PE$std.all <- PE$std.nox
}
final_list$estimates <- PE
}
if (modindices) {
final_list$modindices <- lavaan:::modificationIndices(object, standardized = TRUE)
}
final_list
devtools::load_all()
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
fig.path = "man/figures/README-",
out.width = "100%"
)
library(lavaan)
model <- "
# latent variables
ind60 =~ x1 + x2 + x3
dem60 =~ y1 + y2 + y3 + y4
dem65 =~ y5 + y6 + y7 + y8
# regressions
dem60 ~ ind60
dem65 ~ ind60 + dem60
# residual covariances
y1 ~~ y5
y2 ~~ y4 + y6
y3 ~~ y7
y4 ~~ y8
y6 ~~ y8"
fit <- sem(model, data=PoliticalDemocracy)
summary_lavaan()
summary_lavaan(fit)
devtools::check()
devtools::check()
var
rowSums
split
devtools::check()
Map
devtools::check()
devtools::check()
devtools::check()
library(lavaan)
devtools::load_all()
basemetric <- 'tefficacy=~ 1*lkredcc + c(a1,a,a,a,a5,a,a,a,a,a10,a,a,a,a,a15,a,a)*ownrdcc
cefficacy=~ 1*lklmten + c(b,b,b,b,b,b,b,b,b,b,b,b,b,b,b,b,b)*gvsrdcc
tefficacy ~~ tefficacy
tefficacy ~ 1
cefficacy ~~ cefficacy
cefficacy ~ 1
gvsrdcc ~~ gvsrdcc
lkredcc ~~ lkredcc
lklmten ~~ lklmten
ownrdcc ~~ ownrdcc
gvsrdcc ~ c(c,c,c,c,c5,c,c,c,c,c,c,c,c,c,c,c,c)*1
ownrdcc ~ c(d1,d,d,d,d5,d,d,d,d,d10,d,d,d,d,d15,d,d17)*1
tefficacy ~~ cefficacy
'
noCZ <- read.csv("./Downloads/andre_lavaan/noCZ.csv")
noCZ <- read.csv("noCZ.csv")
m1 <-lavaan(basemetric, data=noCZ,
group="cntry",
auto.fix.first=F,
auto.var=F,
auto.cov.y=F)
group_qsscore(m1)
group_qsscore(m1)
#' Calculate quality of latent variable sum scores by groups
#'
#' @param model A lavaan model
#'
#' @return A data frame
#' @export
group_qsscore <- function(model, countries) {
# Grab original data and name columns
# I don't calculate the variance yet because
# I need to know why variables were composing the
# composite score.
df_names <- lavaan::lavNames(model)
cnt_dt <- lapply(lavaan::inspect(model, "data"), todf, some_names = df_names)
# Get all the estimates, separate by country
# and name the list w/ country names
pooled_est <- summary_lavaan(model, standardized = TRUE)$estimates
sep_est <- split(pooled_est, pooled_est$group)
names(sep_est) <- names(cnt_dt)
latent_sep <- lapply(sep_est, country_latent)
cnt_quality <- Map(vec_subsetting_lat, latent_sep, cnt_dt)
final_df <- cbind(groups = names(cnt_quality), Reduce(rbind, cnt_quality))
if (!missing(countries)) {
final_df <- final_df[final_df$countries %in% countries, ]
}
final_df
}
devtools::load_all()
group_qsscore(m1, c("PL", "NO"))
group_qsscore(m1)
dt <- group_qsscore(m1)
dt$groups
dt$groups %in% c("AT")
dt[dt$groups %in% c("AT"), ]
m1 <-lavaan(basemetric, data=noCZ,
group="cntry",
auto.fix.first=F,
auto.var=F,
auto.cov.y=F)
group_qsscore(m1, c("PL", "NO"))
group_qsscore(m1)
group_qsscore(m1, "AT")
model <- m1
countries <- "AT"
df_names <- lavaan::lavNames(model)
cnt_dt <- lapply(lavaan::inspect(model, "data"), todf, some_names = df_names)
# Get all the estimates, separate by country
# and name the list w/ country names
pooled_est <- summary_lavaan(model, standardized = TRUE)$estimates
sep_est <- split(pooled_est, pooled_est$group)
names(sep_est) <- names(cnt_dt)
latent_sep <- lapply(sep_est, country_latent)
cnt_quality <- Map(vec_subsetting_lat, latent_sep, cnt_dt)
final_df <- cbind(groups = names(cnt_quality), Reduce(rbind, cnt_quality))
final_df
final_df$countries %in% countries
final_df$countries
#' Calculate quality of latent variable sum scores by groups
#'
#' @param model A lavaan model
#'
#' @return A data frame
#' @export
group_qsscore <- function(model, countries) {
# Grab original data and name columns
# I don't calculate the variance yet because
# I need to know why variables were composing the
# composite score.
df_names <- lavaan::lavNames(model)
cnt_dt <- lapply(lavaan::inspect(model, "data"), todf, some_names = df_names)
# Get all the estimates, separate by country
# and name the list w/ country names
pooled_est <- summary_lavaan(model, standardized = TRUE)$estimates
sep_est <- split(pooled_est, pooled_est$group)
names(sep_est) <- names(cnt_dt)
latent_sep <- lapply(sep_est, country_latent)
cnt_quality <- Map(vec_subsetting_lat, latent_sep, cnt_dt)
final_df <- cbind(groups = names(cnt_quality), Reduce(rbind, cnt_quality))
if (!missing(countries)) {
final_df <- final_df[final_df$groups %in% countries, ]
}
final_df
}
library(lavaan)
devtools::load_all()
basemetric <- 'tefficacy=~ 1*lkredcc + c(a1,a,a,a,a5,a,a,a,a,a10,a,a,a,a,a15,a,a)*ownrdcc
cefficacy=~ 1*lklmten + c(b,b,b,b,b,b,b,b,b,b,b,b,b,b,b,b,b)*gvsrdcc
tefficacy ~~ tefficacy
tefficacy ~ 1
cefficacy ~~ cefficacy
cefficacy ~ 1
gvsrdcc ~~ gvsrdcc
lkredcc ~~ lkredcc
lklmten ~~ lklmten
ownrdcc ~~ ownrdcc
gvsrdcc ~ c(c,c,c,c,c5,c,c,c,c,c,c,c,c,c,c,c,c)*1
ownrdcc ~ c(d1,d,d,d,d5,d,d,d,d,d10,d,d,d,d,d15,d,d17)*1
tefficacy ~~ cefficacy
'
noCZ <- read.csv("noCZ.csv")
m1 <-lavaan(basemetric, data=noCZ,
group="cntry",
auto.fix.first=F,
auto.var=F,
auto.cov.y=F)
group_qsscore(m1, "AT")
group_qsscore(m1, c("AT", "PL"))
group_qsscore(m1)
group_qsscore(m1, c("AT", "NL", "PL"))
group_qsscore(m1, "IS")
